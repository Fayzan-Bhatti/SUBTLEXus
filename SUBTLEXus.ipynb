{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import random\n",
    "from collections import Counter, defaultdict\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import some necessary packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"C:/Users/georg/_CompLing/subtlexus2/SUBTLEXus.txt\" , header = 0, delim_whitespace = True) # load SUBTLEX  \n",
    "types = list(data['Word'])                       # list of types = words from dataframe\n",
    "freqs = list(data['FREQcount'])                  # get frequencies of all words into a list\n",
    "tokens = []                                      # initiate empty  list of tokens\n",
    "for word, freq in zip(types, freqs):\n",
    "    i = freq\n",
    "    while i > 0:                                 # append each word in types to the list of tokens i times where i is it's \n",
    "        tokens.append(word)                      # frequency as stated in the dataframe\n",
    "        i -= 1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>FREQcount</th>\n",
       "      <th>CDcount</th>\n",
       "      <th>FREQlow</th>\n",
       "      <th>Cdlow</th>\n",
       "      <th>SUBTLWF</th>\n",
       "      <th>Lg10WF</th>\n",
       "      <th>SUBTLCD</th>\n",
       "      <th>Lg10CD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the</td>\n",
       "      <td>1501908</td>\n",
       "      <td>8388</td>\n",
       "      <td>1339811</td>\n",
       "      <td>8388</td>\n",
       "      <td>29449.18</td>\n",
       "      <td>6.1766</td>\n",
       "      <td>100.00</td>\n",
       "      <td>3.9237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>to</td>\n",
       "      <td>1156570</td>\n",
       "      <td>8383</td>\n",
       "      <td>1138435</td>\n",
       "      <td>8380</td>\n",
       "      <td>22677.84</td>\n",
       "      <td>6.0632</td>\n",
       "      <td>99.94</td>\n",
       "      <td>3.9235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a</td>\n",
       "      <td>1041179</td>\n",
       "      <td>8382</td>\n",
       "      <td>976941</td>\n",
       "      <td>8380</td>\n",
       "      <td>20415.27</td>\n",
       "      <td>6.0175</td>\n",
       "      <td>99.93</td>\n",
       "      <td>3.9234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>you</td>\n",
       "      <td>2134713</td>\n",
       "      <td>8381</td>\n",
       "      <td>1595028</td>\n",
       "      <td>8376</td>\n",
       "      <td>41857.12</td>\n",
       "      <td>6.3293</td>\n",
       "      <td>99.92</td>\n",
       "      <td>3.9233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>and</td>\n",
       "      <td>682780</td>\n",
       "      <td>8379</td>\n",
       "      <td>515365</td>\n",
       "      <td>8374</td>\n",
       "      <td>13387.84</td>\n",
       "      <td>5.8343</td>\n",
       "      <td>99.89</td>\n",
       "      <td>3.9232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>it</td>\n",
       "      <td>963712</td>\n",
       "      <td>8377</td>\n",
       "      <td>685089</td>\n",
       "      <td>8370</td>\n",
       "      <td>18896.31</td>\n",
       "      <td>5.9839</td>\n",
       "      <td>99.87</td>\n",
       "      <td>3.9231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>s</td>\n",
       "      <td>1057301</td>\n",
       "      <td>8377</td>\n",
       "      <td>1052788</td>\n",
       "      <td>8373</td>\n",
       "      <td>20731.39</td>\n",
       "      <td>6.0242</td>\n",
       "      <td>99.87</td>\n",
       "      <td>3.9231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>of</td>\n",
       "      <td>590439</td>\n",
       "      <td>8375</td>\n",
       "      <td>573021</td>\n",
       "      <td>8372</td>\n",
       "      <td>11577.24</td>\n",
       "      <td>5.7712</td>\n",
       "      <td>99.85</td>\n",
       "      <td>3.9230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>for</td>\n",
       "      <td>351650</td>\n",
       "      <td>8374</td>\n",
       "      <td>332686</td>\n",
       "      <td>8370</td>\n",
       "      <td>6895.10</td>\n",
       "      <td>5.5461</td>\n",
       "      <td>99.83</td>\n",
       "      <td>3.9230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>I</td>\n",
       "      <td>2038529</td>\n",
       "      <td>8372</td>\n",
       "      <td>5147</td>\n",
       "      <td>350</td>\n",
       "      <td>39971.16</td>\n",
       "      <td>6.3093</td>\n",
       "      <td>99.81</td>\n",
       "      <td>3.9229</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Word  FREQcount  CDcount  FREQlow  Cdlow   SUBTLWF  Lg10WF  SUBTLCD  Lg10CD\n",
       "0  the    1501908     8388  1339811   8388  29449.18  6.1766   100.00  3.9237\n",
       "1   to    1156570     8383  1138435   8380  22677.84  6.0632    99.94  3.9235\n",
       "2    a    1041179     8382   976941   8380  20415.27  6.0175    99.93  3.9234\n",
       "3  you    2134713     8381  1595028   8376  41857.12  6.3293    99.92  3.9233\n",
       "4  and     682780     8379   515365   8374  13387.84  5.8343    99.89  3.9232\n",
       "5   it     963712     8377   685089   8370  18896.31  5.9839    99.87  3.9231\n",
       "6    s    1057301     8377  1052788   8373  20731.39  6.0242    99.87  3.9231\n",
       "7   of     590439     8375   573021   8372  11577.24  5.7712    99.85  3.9230\n",
       "8  for     351650     8374   332686   8370   6895.10  5.5461    99.83  3.9230\n",
       "9    I    2038529     8372     5147    350  39971.16  6.3093    99.81  3.9229"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True \n",
      " True\n"
     ]
    }
   ],
   "source": [
    "print(len(tokens) == sum(freqs),'\\n',len(types)==len(freqs))       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the equations above both result to True, it indicates that the list of tokens consists of the same amount of individual tokens as SUBTLEX (the sum of the frequencies of the types) and the list of types contains the same amount of individual types as SUBTLEX (the amount of words in the 'Word' column of SUBTLEX."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Corpus(object):\n",
    "    def __init__(self, n, corpus):                        \n",
    "        self.ngram_size = n\n",
    "        self.corpus = corpus  \n",
    "        self.words = self.read()\n",
    "        \n",
    "        \n",
    "    def read(self):\n",
    "        \n",
    "        \"\"\"The read function gets no arguments except for self. \n",
    "        It takes as inputs all items in the list that is stored in self.corpus\n",
    "        and outputs a list of lists of lowercase letters with the necessary \n",
    "        amount of BoS and EoS symbols added.\"\"\"\n",
    "        \n",
    "        words = []                                                            #initiate empty list \n",
    "        r = 1 if self.ngram_size == 1 else self.ngram_size - 1                #calculate how many #bos# symbols\n",
    "                                                                              # to add to words in the corpus\n",
    "            \n",
    "        for word in self.corpus:                                              #iterate over words in corpus\n",
    "            if isinstance(word,str):                                          #if the word is a string:\n",
    "                words.append(['#bos#']*r + list(word.lower()) + ['#eos#'])    #   add r * #bos# symbols and an #eos# symbol \n",
    "                                                                              #   to the word and make the word a list of letters\n",
    "                                                                              #   append the new form of the word to a wordslist\n",
    "                        \n",
    "        else:                                                                 #if  word is not a string:\n",
    "                words.append(['#bos#']*r + list(str(word)) + ['#eos#'])       #    turn it into a string and add #bos# and #eos#\n",
    "                                                                              #    symbols and append it to the wordslist\n",
    "                \n",
    "        return words                                                          #return the list of words in their new form       \n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I decided to implement Corpus and Language Model as two separate classes. The thought behind this was that this way I could use much of the code provided in Notebook 4 on language modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LM(object):\n",
    "    def __init__(self, n):\n",
    "      \n",
    "        self.k = 0.01 \n",
    "        self.ngram_size = n\n",
    "        self.smoother = 'Laplace'\n",
    "        self.lambdas = {i+1: 1/n for i in range(n)}\n",
    "        \n",
    "    def get_ngram(self, word, i, n):\n",
    "        \n",
    "        if n == 1:\n",
    "            return word[i]\n",
    "        else:\n",
    "            ngram = word[i-(n-1):i+1]\n",
    "            history = tuple(ngram[:-1])\n",
    "            target = ngram[-1]\n",
    "            return (history, target)\n",
    "        \n",
    "        \n",
    "    def update_counts(self, corpus, n):\n",
    "        \n",
    "        \"\"\"\n",
    "        Processes the input corpus given an ngram sizes and stores transition counts. Depending on which smoother\n",
    "        is selected when creating the LM object, different courses of actions are taken. The bottom line is that\n",
    "        a dictionary of dictionary is created, where the first level key indicates the ngram size, the second \n",
    "        level key indicates the history, the third level key indicates the current word, and the value indicates\n",
    "        the history-current word co-occurrence count.\n",
    "        \"\"\"\n",
    "        \n",
    "        if self.ngram_size != corpus.ngram_size:\n",
    "            raise ValueError(\"The corpus was pre-processed considering an ngram size of {} while the \"\n",
    "                             \"language model was created with an ngram size of {}. \\n\"\n",
    "                             \"Please choose the same ngram size for pre-processing the corpus and fitting \"\n",
    "                             \"the model.\".format(corpus.ngram_size, self.ngram_size))\n",
    "        \n",
    "        self.counts = defaultdict(dict)\n",
    "        \n",
    "        ngram_sizes = [n]\n",
    "        for ngram_size in ngram_sizes:\n",
    "            self.counts[ngram_size] = defaultdict(dict) if ngram_size > 1 else Counter()\n",
    "        for word in corpus.words:\n",
    "            for ngram_size in ngram_sizes:\n",
    "                for idx in range(n-1, len(word)):\n",
    "                    ngram = self.get_ngram(word, idx, ngram_size)\n",
    "                    if ngram_size == 1:\n",
    "                        self.counts[ngram_size][ngram] += 1\n",
    "                    else:\n",
    "                        # it's faster to try to do something and catch an exception than to use an if statement to \n",
    "                        # check whether a condition is met beforehand. The if is checked everytime, the exception \n",
    "                        # is only catched the first time, after that everything runs smoothly\n",
    "                        try:\n",
    "                            self.counts[ngram_size][ngram[0]][ngram[1]] += 1\n",
    "                        except KeyError:\n",
    "                            self.counts[ngram_size][ngram[0]][ngram[1]] = 1\n",
    "        \n",
    "        # first loop through the words in the corpus, than loop through each letter in a word\n",
    "        self.vocab = {letter for word in corpus.words for letter in word}\n",
    "        self.vocab_size = len(self.vocab)\n",
    "        \n",
    "    def get_unigram_probability(self, ngram):\n",
    "        \n",
    "        \"\"\"\n",
    "        Takes the counts of the model and calculates a probability for transmissions in the unigram\n",
    "        \"\"\"\n",
    "        \n",
    "        tot = sum(list(self.counts[1].values())) + (self.vocab_size*self.k)\n",
    "        \n",
    "        try:\n",
    "            ngram_count = self.counts[1][ngram] + self.k\n",
    "        except KeyError:\n",
    "            ngram_count = self.k\n",
    "        \n",
    "        return ngram_count/tot\n",
    "    \n",
    "    \n",
    "    def get_laplace_ngram_probability(self, history, target):\n",
    "        \n",
    "        \"\"\"\n",
    "        Takes the counts of the model, ngram history and a target and calculates a probability for transmissions in the\n",
    "        ngram using laplace smoothing with the specifed coefficient k\n",
    "        \"\"\"\n",
    "        \n",
    "        try:\n",
    "            ngram_tot = np.sum(list(self.counts[self.ngram_size][history].values())) + (self.vocab_size*self.k)\n",
    "            try:\n",
    "                transition_count = self.counts[self.ngram_size][history][target] + self.k\n",
    "            except KeyError:\n",
    "                transition_count = self.k\n",
    "        except KeyError:\n",
    "            transition_count = self.k\n",
    "            ngram_tot = self.vocab_size*self.k\n",
    "            \n",
    "        return transition_count/ngram_tot \n",
    "    \n",
    "    def perplexity(self, test_corpus):\n",
    "        \n",
    "        \"\"\"\n",
    "        Uses the estimated language model to process a corpus and computes the perplexity \n",
    "        of the language model over the corpus.\n",
    "        \"\"\"\n",
    "        \n",
    "        probs = []\n",
    "        for word in test_corpus.words:\n",
    "            for idx in range(self.ngram_size-1, len(word)):\n",
    "                ngram = self.get_ngram(word, idx, self.ngram_size)\n",
    "                if self.ngram_size == 1:\n",
    "                    probs.append(self.get_unigram_probability(ngram))\n",
    "                else:\n",
    "                    probs.append(self.get_laplace_ngram_probability(ngram[0], ngram[1]))\n",
    "                        \n",
    "        entropy = np.log2(probs)\n",
    "\n",
    "        # this assertion makes sure that valid probabilities are retrieved, whose log must be <= 0\n",
    "        assert all(entropy <= 0)\n",
    "        \n",
    "        avg_entropy = -1 * (sum(entropy) / len(entropy))\n",
    "        \n",
    "        return pow(2.0, avg_entropy)\n",
    "    \n",
    "    def generate(self, limit):\n",
    "    \n",
    "        \"\"\"\n",
    "        This function takes as input an integer specifying the maximum length of the output. \n",
    "    \n",
    "        The function outputs a sentence (in the form of a list) generated according to the language model.\n",
    "        Generation stops either when an end of sequence symbol is samples or when the limit provided as input is \n",
    "        reached.\n",
    "        \"\"\"\n",
    "    \n",
    "        i = 0\n",
    "        r = 1 if self.ngram_size == 1 else self.ngram_size - 1\n",
    "        n = self.ngram_size\n",
    "        word = ['#bos#']*r\n",
    "        current = word[-(self.ngram_size-1):]\n",
    "    \n",
    "        while i < limit:\n",
    "        \n",
    "            # create a vector of the possible words with relative probabilities: for the unigram model, just \n",
    "            # take each unigram probability, for ngram models of higher orders, condition on the current ngram.\n",
    "            letters = []\n",
    "            probabilities = []\n",
    "            continuations = self.counts[self.ngram_size] if n == 1 else self.counts[self.ngram_size][tuple(current)]\n",
    "            tot = sum(list(continuations.values()))\n",
    "            for w, v in continuations.items():\n",
    "                letters.append(w)\n",
    "                probabilities.append(v/tot)\n",
    "        \n",
    "            # generate a new token according to the probabiity distribution\n",
    "            new = np.random.choice(letters, size=1, p=probabilities)[0]\n",
    "        \n",
    "            # stop generating if we hit an end of sequence token.\n",
    "            if new != '#eos#': \n",
    "                word.append(new) \n",
    "            else: \n",
    "                return ''.join(word[n-1:])\n",
    "        \n",
    "            # update the current ngram to proceed generating and increment the counter so that we don't keep \n",
    "            # generating forever and we can stop if we hit the maximum value we provided as input\n",
    "            current = word[-(n-1):]   \n",
    "            i += 1\n",
    "    \n",
    "        # return the generated sentence if no end of sequence symbol is generated.\n",
    "        return ''.join(word[n-1:])\n",
    "    \n",
    "    \n",
    "    def generate_likeliest(self, limit):\n",
    "    \n",
    "        \"\"\"\n",
    "        This function takes as input an integer specifying the maximum length of the output. \n",
    "    \n",
    "        The function outputs a sentence (in the form of a list) generated according to the language model.\n",
    "        Generation stops either when an end of sequence symbol is samples or when the limit provided as input is \n",
    "        reached.\n",
    "        \"\"\"\n",
    "    \n",
    "        i = 0\n",
    "        r = 1 if self.ngram_size == 1 else self.ngram_size - 1\n",
    "        n = self.ngram_size\n",
    "        word = ['#bos#']*r\n",
    "        current = word[-(self.ngram_size-1):]\n",
    "    \n",
    "        while i < limit:\n",
    "        \n",
    "            # create a vector of the possible words with relative probabilities: for the unigram model, just \n",
    "            # take each unigram probability, for ngram models of higher orders, condition on the current ngram.\n",
    "            letters = []\n",
    "            probabilities = []\n",
    "            continuations = self.counts[self.ngram_size] if n == 1 else self.counts[self.ngram_size][tuple(current)]\n",
    "            tot = sum(list(continuations.values()))\n",
    "            for w, v in continuations.items():\n",
    "                letters.append(w)\n",
    "                probabilities.append(v/tot)\n",
    "        \n",
    "            # generate a new token according to the probabiity distribution, but appending the letter with the\n",
    "            # highest probability, rather than choosing randomly based on the probabiity distribution\n",
    "            new = letters[probabilities.index(max(probabilities))]     \n",
    "        \n",
    "            # stop generating if we hit an end of sequence token.\n",
    "            if new != '#eos#': \n",
    "                word.append(new) \n",
    "            else: \n",
    "                return ''.join(word[n-1:])\n",
    "        \n",
    "            # update the current ngram to proceed generating and increment the counter so that we don't keep \n",
    "            # generating forever and we can stop if we hit the maximum value we provided as input\n",
    "            current = word[-(n-1):]   \n",
    "            i += 1\n",
    "    \n",
    "        # return the generated sentence if no end of sequence symbol is generated.\n",
    "        return ''.join(word[n-1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Here I initiate all 4 models to be used "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The implementation of the 'Update Counts' method is quite memory heavy, so this block of code can take a while time to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 3\n",
    "#trigram token based\n",
    "tri_token_corpus = Corpus(n,tokens)                             #create corpus\n",
    "tri_token_lm = LM(n)                                            #initiate model\n",
    "tri_token_lm.update_counts(tri_token_corpus,n)                  #update model counts using corpus\n",
    "\n",
    "\n",
    "#trigram type based\n",
    "tri_type_corpus = Corpus(n,types)\n",
    "tri_type_lm = LM(n)\n",
    "tri_type_lm.update_counts(tri_type_corpus,n)\n",
    "\n",
    "n = 4\n",
    "#tetragram token based\n",
    "tetra_token_corpus = Corpus(n,tokens)\n",
    "tetra_token_lm = LM(n)\n",
    "tetra_token_lm.update_counts(tetra_token_corpus,n)\n",
    "\n",
    "\n",
    "#tetragram type based\n",
    "tetra_type_corpus = Corpus(n,types)\n",
    "tetra_type_lm = LM(n)\n",
    "tetra_type_lm.update_counts(tetra_type_corpus,n)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create lists of all words of lengths 3, 8 and 13 in SUBTLEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "l3 = []                         #create list\n",
    "for word in types:              #iterate over all words in type\n",
    "    if  isinstance(word,str):   #check if the word is a string(i.e. not a number)\n",
    "        if len(word) == 3:      #filter for words with length 3\n",
    "            l3.append(word)     #append 3 letter words to list\n",
    "        else:\n",
    "            continue\n",
    "    else: \n",
    "        continue\n",
    "        \n",
    "        \n",
    "        \n",
    "l8 = []                         #same as before but for 8 letter words\n",
    "for word in types:\n",
    "    if  isinstance(word,str):\n",
    "        \n",
    "        if len(word) == 8:\n",
    "            l8.append(word)\n",
    "        else:\n",
    "            continue\n",
    "    else: \n",
    "        continue\n",
    "        \n",
    "        \n",
    "l13 = []                        #same as before but for 13 letter words\n",
    "for word in types:\n",
    "    if  isinstance(word,str):\n",
    "        \n",
    "        if len(word) == 13:\n",
    "            l13.append(word)\n",
    "        else:\n",
    "            continue\n",
    "    else: \n",
    "        continue\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate lists to store the data which will be put into dataframe\n",
    "perplexities = []\n",
    "words = []\n",
    "n_gram_size = []\n",
    "input_data = []\n",
    "from itertools import cycle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the lowest perplexity words for each language model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trigram token based model - find lowest perplexity words\n",
    "dictperp3 = {}                                            #initiate dictionaries to store key-value pairs\n",
    "dictperp8 = {}                                            #keys are words and values are the perplexities for those words\n",
    "dictperp13 = {}                                           #the number in the name of the dictionary specifies word length\n",
    "n = 3                                                     #specify n-gram size\n",
    "inp = 'token'                                             #specify input type\n",
    "\n",
    "\n",
    "for i in l3:                                              #loop over 3 letter words\n",
    "    test_corpus = Corpus(n, [i])                          #create a corpus consisting of one word\n",
    "    perplexity3 = tri_token_lm.perplexity(test_corpus)    #calculate perplexity of model when fed that corpus/word\n",
    "    dictperp3[i] = perplexity3                            #add word and perplexity to dictionary  of 3 letter words \n",
    "                                                          #and their perplexities\n",
    "\n",
    "for j in l8:                                              #same for 8 letter words\n",
    "    test_corpus = Corpus(n, [j])\n",
    "    perplexity8 = tri_token_lm.perplexity(test_corpus)\n",
    "    dictperp8[j] = perplexity8\n",
    "\n",
    "\n",
    "for k in l13:                                             #same for 13 letter words\n",
    "    test_corpus = Corpus(n, [k])\n",
    "    perplexity13 = tri_token_lm.perplexity(test_corpus)\n",
    "    dictperp13[k] = perplexity13\n",
    "    \n",
    "min_perp3 = (min(dictperp3.values()))                     #find smallest perplexity from dictionary of 3 letter words\n",
    "word_3 = min(dictperp3, key=dictperp3.get)                #get the corresponding 3 letter word \n",
    "\n",
    "min_perp8 = (min(dictperp8.values()))\n",
    "word_8 = min(dictperp8, key=dictperp8.get)\n",
    "\n",
    "min_perp13 = (min(dictperp13.values()))\n",
    "word_13 = min(dictperp13, key=dictperp13.get)\n",
    "\n",
    "perplexities.append(min_perp3)                             #append all the perplexities to a list \n",
    "perplexities.append(min_perp8)\n",
    "perplexities.append(min_perp13)\n",
    "\n",
    "words.append(word_3)                                       #append all the words to a words list\n",
    "words.append(word_8)\n",
    "words.append(word_13)\n",
    "\n",
    "n_gram_size.append(n)                                      #append the n-gram sizes to a list\n",
    "n_gram_size.append(n)\n",
    "n_gram_size.append(n)\n",
    "\n",
    "input_data.append(inp )                                    #append the input data type to a list\n",
    "input_data.append(inp )\n",
    "input_data.append(inp )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The process for the rest  of the models is exactly the same, so I will not comment it again\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trigram type based model - find lowest perplexity words\n",
    "dictperp3 = {}\n",
    "dictperp8 = {}\n",
    "dictperp13 = {}\n",
    "n = 3\n",
    "inp = 'type'\n",
    "for i in l3 :\n",
    "    test_corpus = Corpus(n, [i])\n",
    "    perplexity3 = tri_type_lm.perplexity(test_corpus)\n",
    "    dictperp3[i] = perplexity3\n",
    "for j in l8:\n",
    "    test_corpus = Corpus(n, [j])\n",
    "    perplexity8 = tri_type_lm.perplexity(test_corpus)\n",
    "    dictperp8[j] = perplexity8\n",
    "for k in l13:\n",
    "    test_corpus = Corpus(n, [k])\n",
    "    perplexity13 = tri_type_lm.perplexity(test_corpus)\n",
    "    dictperp13[k] = perplexity13\n",
    "    \n",
    "min_perp3 = (min(dictperp3.values()))\n",
    "word_3 = min(dictperp3, key=dictperp3.get)\n",
    "min_perp8 = (min(dictperp8.values()))\n",
    "word_8 = min(dictperp8, key=dictperp8.get)\n",
    "min_perp13 = (min(dictperp13.values()))\n",
    "word_13 = min(dictperp13, key=dictperp13.get)\n",
    "\n",
    "perplexities.append(min_perp3)\n",
    "perplexities.append(min_perp8)\n",
    "perplexities.append(min_perp13)\n",
    "\n",
    "words.append(word_3)\n",
    "words.append(word_8)\n",
    "words.append(word_13)\n",
    "\n",
    "n_gram_size.append(n)\n",
    "n_gram_size.append(n)\n",
    "n_gram_size.append(n)\n",
    "\n",
    "input_data.append(inp )\n",
    "input_data.append(inp )\n",
    "input_data.append(inp )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#tetragram token based model - find lowest perplexity words\n",
    "dictperp3 = {}\n",
    "dictperp8 = {}\n",
    "dictperp13 = {}\n",
    "n = 4\n",
    "inp = 'token'\n",
    "for i in l3:\n",
    "    test_corpus = Corpus(n, [i])\n",
    "    perplexity3 = tetra_token_lm.perplexity(test_corpus)\n",
    "    dictperp3[i] = perplexity3\n",
    "for j in l8:\n",
    "    test_corpus = Corpus(n, [j])\n",
    "    perplexity8 = tetra_token_lm.perplexity(test_corpus)\n",
    "    dictperp8[j] = perplexity8\n",
    "for k in l13:\n",
    "    test_corpus = Corpus(n, [k])\n",
    "    perplexity13 = tetra_token_lm.perplexity(test_corpus)\n",
    "    dictperp13[k] = perplexity13\n",
    "    \n",
    "min_perp3 = (min(dictperp3.values()))\n",
    "word_3 = min(dictperp3, key=dictperp3.get)\n",
    "min_perp8 = (min(dictperp8.values()))\n",
    "word_8 = min(dictperp8, key=dictperp8.get)\n",
    "min_perp13 = (min(dictperp13.values()))\n",
    "word_13 = min(dictperp13, key=dictperp13.get)\n",
    "\n",
    "perplexities.append(min_perp3)\n",
    "perplexities.append(min_perp8)\n",
    "perplexities.append(min_perp13)\n",
    "\n",
    "words.append(word_3)\n",
    "words.append(word_8)\n",
    "words.append(word_13)\n",
    "n_gram_size.append(n)\n",
    "n_gram_size.append(n)\n",
    "n_gram_size.append(n)\n",
    "\n",
    "input_data.append(inp )\n",
    "input_data.append(inp )\n",
    "input_data.append(inp )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tetragram type based model - find lowest perplexity words\n",
    "dictperp3 = {}\n",
    "dictperp8 = {}\n",
    "dictperp13 = {}\n",
    "n = 4\n",
    "inp = 'type'\n",
    "for i in l3:\n",
    "    test_corpus = Corpus(n, [i])\n",
    "    perplexity3 = tetra_type_lm.perplexity(test_corpus)\n",
    "    dictperp3[i] = perplexity3\n",
    "\n",
    "for j in l8:\n",
    "    test_corpus = Corpus(n, [j])\n",
    "    perplexity8 = tetra_type_lm.perplexity(test_corpus)\n",
    "    dictperp8[j] = perplexity8\n",
    "for k in l13:\n",
    "    test_corpus = Corpus(n, [k])\n",
    "    perplexity13 = tetra_type_lm.perplexity(test_corpus)\n",
    "    dictperp13[k] = perplexity13\n",
    "    \n",
    "min_perp3 = (min(dictperp3.values()))\n",
    "word_3 = min(dictperp3, key=dictperp3.get)\n",
    "min_perp8 = (min(dictperp8.values()))\n",
    "word_8 = min(dictperp8, key=dictperp8.get)\n",
    "min_perp13 = (min(dictperp13.values()))\n",
    "word_13 = min(dictperp13, key=dictperp13.get)\n",
    "\n",
    "perplexities.append(min_perp3)\n",
    "perplexities.append(min_perp8)\n",
    "perplexities.append(min_perp13)\n",
    "\n",
    "words.append(word_3)\n",
    "words.append(word_8)\n",
    "words.append(word_13)\n",
    "\n",
    "n_gram_size.append(n)\n",
    "n_gram_size.append(n)\n",
    "n_gram_size.append(n)\n",
    "\n",
    "input_data.append(inp )\n",
    "input_data.append(inp )\n",
    "input_data.append(inp )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Insert all the lists into a dataframe and display that dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_gram_size</th>\n",
       "      <th>input_data</th>\n",
       "      <th>perplexities</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>token</td>\n",
       "      <td>2.451944</td>\n",
       "      <td>you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>token</td>\n",
       "      <td>3.681957</td>\n",
       "      <td>anything</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>token</td>\n",
       "      <td>4.900838</td>\n",
       "      <td>motherfucking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>type</td>\n",
       "      <td>3.239946</td>\n",
       "      <td>ing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>type</td>\n",
       "      <td>4.053892</td>\n",
       "      <td>mentions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>type</td>\n",
       "      <td>4.384162</td>\n",
       "      <td>fractionating</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>token</td>\n",
       "      <td>2.196918</td>\n",
       "      <td>you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "      <td>token</td>\n",
       "      <td>2.524541</td>\n",
       "      <td>anything</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4</td>\n",
       "      <td>token</td>\n",
       "      <td>3.249898</td>\n",
       "      <td>backgrounders</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4</td>\n",
       "      <td>type</td>\n",
       "      <td>5.290520</td>\n",
       "      <td>man</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4</td>\n",
       "      <td>type</td>\n",
       "      <td>3.095979</td>\n",
       "      <td>stations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4</td>\n",
       "      <td>type</td>\n",
       "      <td>2.787650</td>\n",
       "      <td>sexualization</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    n_gram_size input_data  perplexities          words\n",
       "0             3      token      2.451944            you\n",
       "1             3      token      3.681957       anything\n",
       "2             3      token      4.900838  motherfucking\n",
       "3             3       type      3.239946            ing\n",
       "4             3       type      4.053892       mentions\n",
       "5             3       type      4.384162  fractionating\n",
       "6             4      token      2.196918            you\n",
       "7             4      token      2.524541       anything\n",
       "8             4      token      3.249898  backgrounders\n",
       "9             4       type      5.290520            man\n",
       "10            4       type      3.095979       stations\n",
       "11            4       type      2.787650  sexualization"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(list(zip( n_gram_size, input_data,perplexities,words)),\n",
    "                  columns = [ \"n_gram_size\", \"input_data\",\"perplexities\",\"words\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at  the perplexities it becomes evident that the least perplexing words for each model are slightly less perplexing to token based models to type based models. This is probably because token based models have 'seen' more words and have transmission probabilites that slightly better model the english language as a result.\n",
    "\n",
    "Words ending in 'ing' seemed to give low perplexities in all models except for the type based tetragram model. This is quite logical, as 'ing' is a very common ending for verbs and nouns alike and verbs that end with 'ing' are very usual in dialogue, which is what SUBTLEX largely consists of. \n",
    "\n",
    "The word 'you' appearing as the 3 letter word with the lowest perplexity in token based models is not at all surprising, as it appears 2.1 million times in the SUBTLEX dataset(more than  4% of the tokens in SUBTLEX are thus 'you')."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_gram_size</th>\n",
       "      <th>input_data</th>\n",
       "      <th>likeliest_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>token</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>type</td>\n",
       "      <td>st</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>token</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>type</td>\n",
       "      <td>stant</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_gram_size input_data likeliest_word\n",
       "0            3      token            the\n",
       "1            3       type             st\n",
       "2            4      token            the\n",
       "3            4       type          stant"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#generate lists for 2 first columns of the dataframe\n",
    "input_data = ['token','type','token','type']\n",
    "n_gram_size = [3,3,4,4]\n",
    "\n",
    "#generate likeliest words for each model, add them to a list\n",
    "likeliest_words = [tri_token_lm.generate_likeliest(50), tri_type_lm.generate_likeliest(50),\n",
    "                    tetra_token_lm.generate_likeliest(50), tetra_type_lm.generate_likeliest(50)]\n",
    "\n",
    "#generate dataframe with model info and likeliest words generated\n",
    "df = pd.DataFrame(list(zip( n_gram_size, input_data,likeliest_words)),\n",
    "                  columns = [ \"n_gram_size\", \"input_data\",\"likeliest_word\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seeing the word 'the' as the likeliest string in the token based models is not very surprising, as out of the 49 million tokens in SUBTLEX, around 1.5 million are 'the'. While it may not be the most popular token ('you' appears 2.1 million times), 'the' is the first three letters in many other very frequently used words such as 'they', 'there', 'then', etc. \n",
    "\n",
    "The fact that type based models generated words beginning with the letter 's' is also expected, as the in the dictionary also the section of words starting with 's' is the longest. It is also logical that the trigram based type model outputs just 'st', as that particular combination of letters is extremely frequently found in the ends of superlative forms of adjectives and as the trigram looks at the previous 2 letters as 'history', the model has no idea that the current word consists of only 'st' and thinks it likely to be the end of a word. This is 'fixed' in the tetragram based model, as it uses 'BoS' and 'st' as history and thus continues to extend the word instead of ending it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0                                                                                  #initiate counter\n",
    "tri_token_words = []                                                                   #initiate lists to store words\n",
    "tri_type_words = []                                                                    #generate by each model\n",
    "tetra_type_words = []\n",
    "tetra_token_words = []\n",
    "while i < 10:                                                                          #have each model generate 10 words and\n",
    "    tri_token_words.append(str(tri_token_lm.generate(50)))                             #append them to their corresponding lists\n",
    "    tetra_token_words.append(str(tetra_token_lm.generate(50)))                       \n",
    "    tri_type_words.append(str(tri_type_lm.generate(50)))\n",
    "    tetra_type_words.append(str(tetra_type_lm.generate(50)))\n",
    "    i+=1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: stringdist in c:\\users\\georg\\anaconda3\\lib\\site-packages (1.0.9)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import module to find Levenshtein distance \n",
    "import sys\n",
    "!{sys.executable} -m pip install stringdist\n",
    "import stringdist\n",
    "\n",
    "stringdist.levenshtein('test', 'testing')   #execute a test to see if the module works properly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances = []                                                                      #initiate list for average Levenshtein\n",
    "                                                                                     #distances\n",
    "    \n",
    "for word in tri_token_words:                                                         #for each word generated:\n",
    "    leven_dist = []\n",
    "    for type_ in types:                                                              #calculate Levenshtein distance for \n",
    "        if isinstance(type_,str):                                                    #each word in types \n",
    "            leven_dist.append([type_,stringdist.levenshtein(word,type_ )])           #add type and Levenshtein distance to a list\n",
    "    leven_dist.sort( key=lambda x: x[1])                                             #sort the list from lowest to highest \n",
    "                                                                                     #based on Levenshtein distances\n",
    "    dist_sum = 0\n",
    "    for x in leven_dist[:20]:                                                        #add up lowest 20 Levenshtein distances\n",
    "        dist_sum += x[1]                                                           \n",
    "                                                                                     #OLD20 = sum of 20 lowest L-distances / 20\n",
    "    distances.append(dist_sum/20)                                                    #append OLD20 for each word generated to \n",
    "                                                                                     # list\n",
    "for word in tri_type_words:\n",
    "    leven_dist = []\n",
    "    for type_ in types:\n",
    "        if isinstance(type_,str):\n",
    "            leven_dist.append([type_,stringdist.levenshtein(word,type_ )])\n",
    "    leven_dist.sort( key=lambda x: x[1])\n",
    "    \n",
    "    dist_sum = 0\n",
    "    for x in leven_dist[:20]:\n",
    "        dist_sum += x[1]\n",
    "\n",
    "    distances.append(dist_sum/20)\n",
    "\n",
    "for word in tetra_token_words:\n",
    "    leven_dist = []\n",
    "    for type_ in types:\n",
    "        if isinstance(type_,str):\n",
    "            leven_dist.append([type_,stringdist.levenshtein(word,type_ )])\n",
    "    leven_dist.sort( key=lambda x: x[1])\n",
    "    \n",
    "    dist_sum = 0\n",
    "    for x in leven_dist[:20]:\n",
    "        dist_sum += x[1]\n",
    "\n",
    "    distances.append(dist_sum/20)\n",
    "\n",
    "for word in tetra_type_words:\n",
    "    leven_dist = []\n",
    "    for type_ in types:\n",
    "        if isinstance(type_,str):\n",
    "            leven_dist.append([type_,stringdist.levenshtein(word,type_ )])\n",
    "    leven_dist.sort( key=lambda x: x[1])\n",
    "    \n",
    "    dist_sum = 0\n",
    "    for x in leven_dist[:20]:\n",
    "        dist_sum += x[1]\n",
    "\n",
    "    distances.append(dist_sum/20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tri_token_perp = np.mean(distances[:10])\n",
    "tri_type_perp = np.mean(distances[10:20])\n",
    "tetra_token_perp = np.mean(distances[20:30])\n",
    "tetra_type_perp = np.mean(distances[30:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_gram_size</th>\n",
       "      <th>input_data</th>\n",
       "      <th>old_20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>token</td>\n",
       "      <td>1.135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>type</td>\n",
       "      <td>2.920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>token</td>\n",
       "      <td>1.205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>type</td>\n",
       "      <td>1.905</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_gram_size input_data  old_20\n",
       "0            3      token   1.135\n",
       "1            3       type   2.920\n",
       "2            4      token   1.205\n",
       "3            4       type   1.905"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distances = [tri_token_perp,tri_type_perp,tetra_token_perp, tetra_type_perp]           #create list of words\n",
    "                                                                                                    #generated by models\n",
    "                                                            \n",
    "n_gram_size =  [3,3,4,4]    #generate lists of model\n",
    "input_data = ['token','type', 'token', 'type']\n",
    "\n",
    "df = pd.DataFrame(list(zip( n_gram_size, input_data, distances)),                    #create dataframe\n",
    "                  columns = [ \"n_gram_size\", \"input_data\",\"old_20\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Token based models tend to generate strings with denser orthographic neighbourhoods. They tend to generate shorter words that more often than not are actual words that exist in the english language. These shorter words have lower OLD20 values because often changing only one or two letters in the word can lead to a new short word, whereas for longer words more changes would have to be made in the form of letter deletions or replacements to receive a new word. \n",
    "\n",
    "Token based models tend to generate shorter strings because the list of tokens contains many instances shorter words with more general meanings that are often used, whereas the types list contains these words just once, which is just as often as longer words with very specific definitions. This accurately depicts what we know from orthotactics - words used more frequently are shorter and carry a more general meaning and longer words tend to be more specific in meaning and less frequently used in natural language.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "english_words = ['mouth', 'dream', 'sun', 'apple', 'bridge', 'mirror', 'sky', 'fish', 'rooster', 'son']\n",
    "basque_words = ['aho', 'amets', 'eguzki', 'sagar', 'zubi', 'mirail', 'zeru', 'arrain', 'oilar', 'seme']\n",
    "czech_words = ['pusa','sen', 'slunce', 'jablko', 'most', 'zrcadlo', 'nebe', 'ryba',  'kohout', 'syn']\n",
    "dutch_words = ['mond', 'droom', 'zon', 'appel', 'brug', 'spiegel', 'hemel', 'vis', 'haan',  'zoon']\n",
    "finnish_words = ['suu', 'uni', 'aurinko', 'omena', 'silta', 'peili', 'taivas', 'kala', 'kukko', 'poika']\n",
    "italian_words = ['bocca', 'sogno', 'sole', 'mela', 'ponte', 'specchio', 'cielo', 'pesce', 'gallo', 'figlio']\n",
    "\n",
    "non_english_words = basque_words + czech_words + dutch_words + finnish_words + italian_words\n",
    "\n",
    "words = ['mouth', 'dream', 'sun', 'apple', 'bridge', 'mirror', 'sky', 'fish', 'rooster', 'son','aho', \n",
    "         'amets', 'eguzki', 'sagar', 'zubi', 'mirail', 'zeru', 'arrain', 'oilar', 'seme',\n",
    "         'pusa','sen', 'slunce', 'jablko', 'most', 'zrcadlo', 'nebe', 'ryba',  'kohout', 'syn',\n",
    "         'mond', 'droom', 'zon', 'appel', 'brug', 'spiegel', 'hemel', 'vis', 'haan',  'zoon',\n",
    "         'suu', 'uni', 'aurinko', 'omena', 'silta', 'peili', 'taivas', 'kala', 'kukko', 'poika',\n",
    "         'bocca', 'sogno', 'sole', 'mela', 'ponte', 'specchio', 'cielo', 'pesce', 'gallo', 'figlio']\n",
    "\n",
    "languages = ['english', 'basque', 'czech','dutch','finnish','italian']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "tri_token_perplexities = []\n",
    "tetra_token_perplexities = []\n",
    "tri_type_perplexities = []\n",
    "tetra_type_perplexities = []\n",
    "for word in non_english_words:                                            #loop over non-english words\n",
    "    tri_corpus = Corpus(3, [word])                                        #append 2 BoS symbols and an EoS symbol to word\n",
    "    tetra_corpus = Corpus(4,[word])                                       #append 3 BoS symbols and an EoS symbol to word\n",
    "    tri_token_perplexities.append(tri_token_lm.perplexity(tri_corpus))    #get perplexities from trigram based models\n",
    "    tri_type_perplexities.append(tri_type_lm.perplexity(tri_corpus))      #    and append them to a list\n",
    "    tetra_token_perplexities.append(tetra_token_lm.perplexity(tetra_corpus))#get perplexities from tetragram based models\n",
    "    tetra_type_perplexities.append(tetra_type_lm.perplexity(tetra_corpus))  #    and append them to a list\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_perplexities = []\n",
    "max_perplexities = []\n",
    "min_concepts = []\n",
    "max_concepts = []\n",
    "words_min_perplexities = []\n",
    "words_max_perplexities = []\n",
    "language = []\n",
    "n_gram_size = ['3','3','4','4']\n",
    "input_data = ['token','type','token','type']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# append lowest perplexity from each model to one list and append the corresponding word to a different list\n",
    "\n",
    "min_perplexities.append(min(tri_token_perplexities))\n",
    "words_min_perplexities.append(non_english_words[tri_token_perplexities.index(min(tri_token_perplexities))])\n",
    "min_perplexities.append(min(tri_type_perplexities))\n",
    "words_min_perplexities.append(non_english_words[tri_type_perplexities.index(min(tri_type_perplexities))])\n",
    "min_perplexities.append(min(tetra_token_perplexities))\n",
    "words_min_perplexities.append(non_english_words[tetra_token_perplexities.index(min(tetra_token_perplexities))])\n",
    "min_perplexities.append(min(tetra_type_perplexities))\n",
    "words_min_perplexities.append(non_english_words[tetra_type_perplexities.index(min(tetra_type_perplexities))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in words_min_perplexities:   #loop over words with minimal perplexities\n",
    "    idx = words.index(word)           #    get the index in the list of all words\n",
    "    lang_counter = 0\n",
    "    while idx > 10:                   #    subtract 10 from index until the index is\n",
    "        idx -= 10                     #        less than 10, to get the concept in English\n",
    "                                      #    (English is at the beginning of the list at indexes 0-9)\n",
    "        lang_counter += 1\n",
    "    min_concepts.append(words[idx])   #    append concepts to a list\n",
    "    language.append(languages[lang_counter])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# append highest perplexity from each model to one list and append the corresponding word to a different list\n",
    "\n",
    "max_perplexities.append(max(tri_token_perplexities))\n",
    "words_max_perplexities.append(non_english_words[tri_token_perplexities.index(max(tri_token_perplexities))])\n",
    "max_perplexities.append(max(tri_type_perplexities))\n",
    "words_max_perplexities.append(non_english_words[tri_type_perplexities.index(max(tri_type_perplexities))])\n",
    "max_perplexities.append(max(tetra_token_perplexities))\n",
    "words_max_perplexities.append(non_english_words[tetra_token_perplexities.index(max(tetra_token_perplexities))])\n",
    "max_perplexities.append(max(tetra_type_perplexities))\n",
    "words_max_perplexities.append(non_english_words[tetra_type_perplexities.index(max(tetra_type_perplexities))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in words_max_perplexities:   #loop over words with minimal perplexities\n",
    "    idx = words.index(word)           #    get the index in the list of all words\n",
    "    lang_counter = 0\n",
    "    while idx > 10:                   #    subtract 10 from index until the index is\n",
    "        idx -= 10                     #        less than 10, to get the concept in English\n",
    "                                      #    (English is at the beginning of the list at indexes 0-9)\n",
    "        lang_counter += 1\n",
    "    max_concepts.append(words[idx])   #    append concepts to a list\n",
    "    language.append(languages[lang_counter])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>N-Gram Size</th>\n",
       "      <th>Input Data</th>\n",
       "      <th>Concepts</th>\n",
       "      <th>Language</th>\n",
       "      <th>Max Perplexity Word</th>\n",
       "      <th>Max Perplexity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>token</td>\n",
       "      <td>mirror</td>\n",
       "      <td>czech</td>\n",
       "      <td>zrcadlo</td>\n",
       "      <td>786.150174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>type</td>\n",
       "      <td>mirror</td>\n",
       "      <td>czech</td>\n",
       "      <td>zrcadlo</td>\n",
       "      <td>121.213535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>token</td>\n",
       "      <td>sky</td>\n",
       "      <td>italian</td>\n",
       "      <td>cielo</td>\n",
       "      <td>2709.020584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>type</td>\n",
       "      <td>sun</td>\n",
       "      <td>basque</td>\n",
       "      <td>eguzki</td>\n",
       "      <td>265.476661</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  N-Gram Size Input Data Concepts Language Max Perplexity Word  Max Perplexity\n",
       "0           3      token   mirror    czech             zrcadlo      786.150174\n",
       "1           3       type   mirror    czech             zrcadlo      121.213535\n",
       "2           4      token      sky  italian               cielo     2709.020584\n",
       "3           4       type      sun   basque              eguzki      265.476661"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(list(zip(n_gram_size, input_data, max_concepts,language[4:], words_max_perplexities,max_perplexities)), \n",
    "                  columns = [\"N-Gram Size\", \"Input Data\", \"Concepts\",\"Language\", \"Max Perplexity Word\",\"Max Perplexity\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The czech word 'zrcadlo' appearing as the word that perplexes trigram models the most is likely due to the fact that it contains two trigrams that appear either never or very infrequently in the english language - 'zrc' which is found in no english word and 'dlo' which appears only in some compound words such as 'landlord' or 'padlock'.\n",
    "As for the tetragram based models, I am not sure why 'cielo' perplexes the token based model as much as it does(which is a lot). Neither of the tetragrams 'ciel' and 'ielo' appear often in  the english language, but it seems quite weird to me that 'cielo' draws a higher perplexity from the model than 'zrcadlo' for instance. The high perplexity for 'eguzki' is understandable, as the transmission between 'k' and 'z' is extremely rare in english (it pretty much only appears in the word 'blitzkrieg' and the sequence of 'eguz' is also highly irregular in english"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>N-Gram Size</th>\n",
       "      <th>Input Data</th>\n",
       "      <th>Concepts</th>\n",
       "      <th>Language</th>\n",
       "      <th>Min Perplexity Word</th>\n",
       "      <th>Min Perplexity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>token</td>\n",
       "      <td>bridge</td>\n",
       "      <td>czech</td>\n",
       "      <td>most</td>\n",
       "      <td>7.158576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>type</td>\n",
       "      <td>sun</td>\n",
       "      <td>italian</td>\n",
       "      <td>sole</td>\n",
       "      <td>7.775624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>token</td>\n",
       "      <td>bridge</td>\n",
       "      <td>czech</td>\n",
       "      <td>most</td>\n",
       "      <td>5.094633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>type</td>\n",
       "      <td>dream</td>\n",
       "      <td>dutch</td>\n",
       "      <td>droom</td>\n",
       "      <td>6.673025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  N-Gram Size Input Data Concepts Language Min Perplexity Word  Min Perplexity\n",
       "0           3      token   bridge    czech                most        7.158576\n",
       "1           3       type      sun  italian                sole        7.775624\n",
       "2           4      token   bridge    czech                most        5.094633\n",
       "3           4       type    dream    dutch               droom        6.673025"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(list(zip(n_gram_size, input_data,min_concepts,language[:4], words_min_perplexities,min_perplexities)), \n",
    "                  columns = [\"N-Gram Size\", \"Input Data\", \"Concepts\",\"Language\",\"Min Perplexity Word\",\"Min Perplexity\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'Most' and 'Sole' are also words in english, so their perplexities are understandably quite low for models trained on an english corpus. 'Droom' - although not a word in english - is quite close to several english words such as 'room' or 'drool'. Furthermroe it does not contain any transmissions between letters or combinations of letters that are not frequently used in english,  resulting in a low perplexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "tri_token_perplexities = []\n",
    "tetra_token_perplexities = []\n",
    "tri_type_perplexities = []\n",
    "tetra_type_perplexities = []\n",
    "\n",
    "for word in words:\n",
    "    tri_corpus = Corpus(3, [word])                                                    #for every word create 2 corpora to test\n",
    "    tetra_corpus = Corpus(4, [word])                                                  #to test with the models(trigram and\n",
    "    tri_token_perplexities.append(tri_token_lm.perplexity(tri_corpus))                #tetragram models need separate corpora)\n",
    "    tri_type_perplexities.append(tri_type_lm.perplexity(tri_corpus))\n",
    "    tetra_token_perplexities.append(tetra_token_lm.perplexity(tetra_corpus))          #calculate perplexities per model \n",
    "    tetra_type_perplexities.append(tetra_type_lm.perplexity(tetra_corpus))            #and append to a list\n",
    "    \n",
    "perp_english = np.mean(tri_token_perplexities[:10])                                   #for each language:\n",
    "perp_basque = np.mean(tri_token_perplexities[10:20])                                  #    average up the perplexities for words\n",
    "perp_czech = np.mean(tri_token_perplexities[20:30])                                   #    in that language and save variables\n",
    "perp_dutch = np.mean(tri_token_perplexities[30:40])\n",
    "perp_finnish = np.mean(tri_token_perplexities[40:50])\n",
    "perp_italian = np.mean(tri_token_perplexities[50:])\n",
    "language_perplexities = [perp_english, perp_basque, perp_czech, perp_dutch, perp_finnish, perp_italian #add perplexities to list\n",
    "\n",
    "perp_english = np.mean(tri_type_perplexities[:10])\n",
    "perp_basque = np.mean(tri_type_perplexities[10:20])\n",
    "perp_czech = np.mean(tri_type_perplexities[20:30])\n",
    "perp_dutch = np.mean(tri_type_perplexities[30:40])\n",
    "perp_finnish = np.mean(tri_type_perplexities[40:50])\n",
    "perp_italian = np.mean(tri_type_perplexities[50:])\n",
    "language_perplexities += [perp_english, perp_basque, perp_czech, perp_dutch, perp_finnish, perp_italian]\n",
    "\n",
    "perp_english = np.mean(tetra_token_perplexities[:10])\n",
    "perp_basque = np.mean(tetra_token_perplexities[10:20])\n",
    "perp_czech = np.mean(tetra_token_perplexities[20:30])\n",
    "perp_dutch = np.mean(tetra_token_perplexities[30:40])\n",
    "perp_finnish = np.mean(tetra_token_perplexities[40:50])\n",
    "perp_italian = np.mean(tetra_token_perplexities[50:])\n",
    "language_perplexities += [perp_english, perp_basque, perp_czech, perp_dutch, perp_finnish, perp_italian]\n",
    "\n",
    "perp_english = np.mean(tetra_type_perplexities[:10])\n",
    "perp_basque = np.mean(tetra_type_perplexities[10:20])\n",
    "perp_czech = np.mean(tetra_type_perplexities[20:30])\n",
    "perp_dutch = np.mean(tetra_type_perplexities[30:40])\n",
    "perp_finnish = np.mean(tetra_type_perplexities[40:50])\n",
    "perp_italian = np.mean(tetra_type_perplexities[50:])\n",
    "language_perplexities += [perp_english, perp_basque, perp_czech, perp_dutch, perp_finnish, perp_italian]\n",
    "\n",
    "n_gramsize = [3,3,3,3,3,3,3,3,3,3,3,3,4,4,4,4,4,4,4,4,4,4,4,4,]\n",
    "inputdata = ['token','token','token','token','token','token','type','type','type','type','type','type',\n",
    "             'token','token','token','token','token','token','type','type','type','type','type','type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_gram_size</th>\n",
       "      <th>input_data</th>\n",
       "      <th>language</th>\n",
       "      <th>average_perplexity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>token</td>\n",
       "      <td>english</td>\n",
       "      <td>13.152731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>token</td>\n",
       "      <td>basque</td>\n",
       "      <td>134.651118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>token</td>\n",
       "      <td>czech</td>\n",
       "      <td>140.829670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>token</td>\n",
       "      <td>dutch</td>\n",
       "      <td>47.456496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>token</td>\n",
       "      <td>finnish</td>\n",
       "      <td>160.789513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>token</td>\n",
       "      <td>italian</td>\n",
       "      <td>28.159439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>type</td>\n",
       "      <td>english</td>\n",
       "      <td>10.275433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>type</td>\n",
       "      <td>basque</td>\n",
       "      <td>34.700293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>type</td>\n",
       "      <td>czech</td>\n",
       "      <td>32.750262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>type</td>\n",
       "      <td>dutch</td>\n",
       "      <td>17.384658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3</td>\n",
       "      <td>type</td>\n",
       "      <td>finnish</td>\n",
       "      <td>32.016032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3</td>\n",
       "      <td>type</td>\n",
       "      <td>italian</td>\n",
       "      <td>15.939692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4</td>\n",
       "      <td>token</td>\n",
       "      <td>english</td>\n",
       "      <td>8.518974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4</td>\n",
       "      <td>token</td>\n",
       "      <td>basque</td>\n",
       "      <td>267.917979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4</td>\n",
       "      <td>token</td>\n",
       "      <td>czech</td>\n",
       "      <td>523.015132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4</td>\n",
       "      <td>token</td>\n",
       "      <td>dutch</td>\n",
       "      <td>45.834927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4</td>\n",
       "      <td>token</td>\n",
       "      <td>finnish</td>\n",
       "      <td>253.117216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4</td>\n",
       "      <td>token</td>\n",
       "      <td>italian</td>\n",
       "      <td>407.386644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>4</td>\n",
       "      <td>type</td>\n",
       "      <td>english</td>\n",
       "      <td>8.113288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>4</td>\n",
       "      <td>type</td>\n",
       "      <td>basque</td>\n",
       "      <td>54.916554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>4</td>\n",
       "      <td>type</td>\n",
       "      <td>czech</td>\n",
       "      <td>69.506040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>4</td>\n",
       "      <td>type</td>\n",
       "      <td>dutch</td>\n",
       "      <td>18.953510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>4</td>\n",
       "      <td>type</td>\n",
       "      <td>finnish</td>\n",
       "      <td>52.965258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>4</td>\n",
       "      <td>type</td>\n",
       "      <td>italian</td>\n",
       "      <td>51.296234</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    n_gram_size input_data language  average_perplexity\n",
       "0             3      token  english           13.152731\n",
       "1             3      token   basque          134.651118\n",
       "2             3      token    czech          140.829670\n",
       "3             3      token    dutch           47.456496\n",
       "4             3      token  finnish          160.789513\n",
       "5             3      token  italian           28.159439\n",
       "6             3       type  english           10.275433\n",
       "7             3       type   basque           34.700293\n",
       "8             3       type    czech           32.750262\n",
       "9             3       type    dutch           17.384658\n",
       "10            3       type  finnish           32.016032\n",
       "11            3       type  italian           15.939692\n",
       "12            4      token  english            8.518974\n",
       "13            4      token   basque          267.917979\n",
       "14            4      token    czech          523.015132\n",
       "15            4      token    dutch           45.834927\n",
       "16            4      token  finnish          253.117216\n",
       "17            4      token  italian          407.386644\n",
       "18            4       type  english            8.113288\n",
       "19            4       type   basque           54.916554\n",
       "20            4       type    czech           69.506040\n",
       "21            4       type    dutch           18.953510\n",
       "22            4       type  finnish           52.965258\n",
       "23            4       type  italian           51.296234"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(list(zip( n_gramsize, inputdata,languages*4,language_perplexities)),\n",
    "                  columns = [ \"n_gram_size\", \"input_data\",\"language\",\"average_perplexity\"])\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All models seem to 'agree' that basque, czech and finnish are more different from english than dutch and italian. This lines up well with what we know of the origins and families of these languages - english and dutch are both west germanic languages. Italian and english are somewhat similar in that they both have many words with latin origins. The rest are however quite distant from english, with finnish being in the finno-ugric language family, czech is slavic and basque is totally unrelated to any other language in the world. \n",
    "\n",
    "The differences in perplexities are bigger for token based models because the frequency distribution of tokens more accurately represent english in how it is realistically used than the even distribution of frequencies of types (1 occurrance per word)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
